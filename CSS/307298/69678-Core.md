# [Core 文件](https://www.cnblogs.com/dongzhiquan/archive/2012/01/20/2328355.html)

## Core 文件介绍

* core dump 文件
* 程序崩溃时，内核把该程序当前内存映射到core文件中，方便定位程序出错问题；

* core文件内容主要包含**内存映像+调试信息**。



## 相关命令

### file

* 查看生成core文件的相关信息，如出错的程序等

```bash
[root @rabbitmq1 /cloud/dahua/core]# file core-Datanode.14563 
core-Datanode.14563: ELF 64-bit LSB core file x86-64, version 1 (SYSV), SVR4-style, from '/cloud/dahua/EFS/Datanode/Bin/Datanode -f /cloud/dahua/EFS/Datanode/Config/DNCo', real uid: 0, effective uid: 0, real gid: 0, effective gid: 0, execfn: '/cloud/dahua/EFS/Datanode/Bin/Datanode', platform: 'x86_64'
```

### ulimit

* [ulimit](https://blog.csdn.net/huangyimo/article/details/79156286) 通过一些参数选项来管理不同种类的系统资源

* 查看生成core文件的开关是否开启，第一行

  ```bash
  [root @rabbitmq1 /cloud/dahua/core]# ulimit -a
  core file size          (blocks, -c) unlimited		//最大core文件的大小，单位blocks 
  data seg size           (kbytes, -d) unlimited		//进程最大的数据段的大小,单位KB
  scheduling priority             (-e) 0				
  file size               (blocks, -f) unlimited		//创建文件的最大值,单位blocks
  pending signals                 (-i) 127142
  max locked memory       (kbytes, -l) 64				//设置在内存中锁定进程的最大值,kB
  max memory size         (kbytes, -m) unlimited		//最大内存大小，kB
  open files                      (-n) 10240			//可打开的最大文件描述符的数量
  pipe size            (512 bytes, -p) 8				//管道缓冲区的最大值
  POSIX message queues     (bytes, -q) 819200
  real-time priority              (-r) 0
  stack size              (kbytes, -s) 8192			//堆栈的最大值,kB
  cpu time               (seconds, -t) unlimited		//CPU使用时间的最大上限,s
  max user processes              (-u) 127142			//最多可开启的程序数目
  virtual memory          (kbytes, -v) unlimited		//虚拟内存的最大值,kB
  file locks                      (-x) unlimited
  ```

  * 说明：第一行core文件大小为0表示没有开启，为 unlimited 说明不限制core文件大小，后面-c、-d等可以设置

* 设置系统允许生成的core文件大小，单位为k，unlimited 为不限制大小

  ```bash
  [root @rabbitmq1 /cloud/dahua/core]# ulimit -c 100
  You have mail in /var/spool/mail/root
  [root @rabbitmq1 /cloud/dahua/core]# ulimit -a
  core file size          (blocks, -c) 100
  ......
  ```
  
* 永久设置core文件：在 /etc/profile 中添加上面相关命令

## 文件路径和命名规则

### core文件存储路径

* /proc/sys/kernel/core_pattern 可以设置保存的路径和文件名

  ```bash
  [root @rabbitmq1 /cloud/dahua/core]# cat /proc/sys/kernel/core_pattern 
  /cloud/dahua/core/core-%e.%p
  ```
  * 参数列表
  
  ```
      %p - 添加dump进程的pid
      %u - 添加dump进程的uid
      %g - 添加dump进程的gid
      %s - 添加导致core dump的信号
      %t - 添加core文件生成时的unix时间
      %h - 添加主机名
      %e - 添加命令名/程序名
      %c - 转储文件的大小上限
  ```
  
  
  
* /proc/sys/kernel/core_uses_pid 可以设置core文件名后面是否添加 pid，添加则为1，否则为0

  ```bash
  [root @rabbitmq1 /cloud/dahua/core]# cat /proc/sys/kernel/core_uses_pid 
  1
  ```

* 永久设置路径和名称：/etc/sysctl.conf 中添加

  ```she
  kernel.core_pattern=/cloud/dahua/core/core-%e.%p
  kernel.core_uses_pid=1
  ```

## core文件调试

* 在core文件所在目录，gdb调试

```bash
[root @rabbitmq1 /cloud/dahua/core]# gdb -c core-Datanode.14563 
......
[New LWP 20026]
[New LWP 14589]
[New LWP 14590]
Missing separate debuginfo for the main executable file
Try: yum --enablerepo='*debug*' install /usr/lib/debug/.build-id/87/edf0e3c1ac3544d2572145398be62025e237ec
Core was generated by `/cloud/dahua/EFS/Datanode/Bin/Datanode -f /cloud/dahua/EFS/Datanode/Config/DNCo'.
Program terminated with signal 6, Aborted.
#0  0x00007eff02453337 in ?? ()

[root @rabbitmq1 /cloud/dahua/core]# gdb Datanode core-Datanode.14563 
......
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
Core was generated by `/cloud/dahua/EFS/Datanode/Bin/Datanode -f /cloud/dahua/EFS/Datanode/Config/DNCo'.
Program terminated with signal 6, Aborted.
#0  0x00007eff02453337 in raise () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install glibc-2.17-292.el7.x86_64 libgcc-4.8.5-39.el7.x86_64 libstdc++-4.8.5-39.el7.x86_64
```

## 产生core文件的[Unix信号](http://www.cppblog.com/loky/archive/2008/12/10/69106.html)

| 名字    | 说明                        | ANSI C POSIX.1 | SVR4 4.3+BSD | 缺省动作   |
| ------- | --------------------------- | -------------- | ------------ | ---------- |
| SIGABRT | 异常终止(abort)             | .    .         | .   .        | 终止w/core |
| SIGBUS  | 硬件故障                    | .              | .   .        | 终止w/core |
| SIGEMT  | 硬件故障                    |                | .   .        | 终止w/core |
| SIGFPE  | 算术异常                    | .    .         | .   .        | 终止w/core |
| SIGILL  | 非法硬件指令                | .    .         | .   .        | 终止w/core |
| SIGIOT  | 硬件故障                    |                | .   .        | 终止w/core |
| SIGQUIT | 终端退出符                  | .              | .   .        | 终止w/core |
| SIGSEGV | 无效存储访问                | .    .         | .   .        | 终止w/core |
| SIGSYS  | 无效系统调用                |                | .   .        | 终止w/core |
| SIGTRAP | 硬件故障                    |                | .   .        | 终止w/core |
| SIGXCPU | 超过CPU限制(setrlimit)      |                | .   .        | 终止w/core |
| SIGXFSZ | 超过文件长度限制(setrlimit) |                | .   .        | 终止w/core |



# core文件清理任务

[redmine](http://10.31.17.179/redmine/issues/69678)

【core文件清理】DN纯软部署场景下core文件数量进行控制

## 描述

DN纯软部署场景下core文件数量进行控制

* 背景：

  ```
  【阿尔及利亚视频云】    
  现场为纯软部署子节，core文件把根目录写满
  目前7.2版本无针对DN的纯软部署包，使用管理节点系统包时，节点无对应清理脚本    
  修改系统core文件生成规则
  ```

* 涉及产品包：

  ```
  - x86:DH_CSS-SYS_CSS-X86-D
  - arm:DH_CSS-ICS_CSS-AARCH-D
  ```

* 要求：

  ```
  1. 了解系统中生产core的场景，core文件命名规则及core文件生成路径的设置；
  2. 查看DH_CSS-SYS_CSS-X86-D及DH_CSS-ICS_CSS-AARCH-D包中core文件规则及core文件路径设置；
  3. 增加core文件清理脚本
  ```

* 参考：DH_CSS-SYS_CSS73IA-VCS    CoreFileCleaner.sh

## 步骤

- x86:DH_CSS-SYS_CSS-X86-D
- arm:DH_CSS-ICS_CSS-AARCH-D

### core路径和命名规则确认

* 产品包目录下 `Kernel/install_kernel` 

  ```shell
  sed -i "/kernel.core_pattern=/d" $sysctl_path
  echo "kernel.core_pattern=/cloud/dahua/core/core-%e.%p" >> $sysctl_path
  mkdir -p /cloud/dahua/core/
  ```

* 目录为 ` /cloud/dahua/core/`
* 命名规则为 `core-%e.%p"`

### 查看core文件大小设置

* 产品包目录下`OS/profile`

  ```shell
  ulimit -c unlimited
  ```

* core文件大小无限制

### core文件清理脚本学习

* 目录 ：`OS/command/CoreFileCleaner.sh`

```shell
while true; do
	check_log_file
	clear_core_files
	check_path_size $CORE_PATH $CORE_PATH_LIMIT_SIZE && clear_all_core_files
	sleep $checkInterval
done &
```

* check_log_file
  * log_file 最大50MB，**超出则使用新日志直接覆盖**
    `/cloud/share/log/datanode_space_cleaner.log`
* clear_core_files
  * 同名不同pid的core文件做多有3个，超出则删除最先创建的
* check_path_size和clear_all_core_files
  * CORE_PATH_LIMIT_SIZE  core目录最大大小为 10G
  * df 可用 超过limit 就执行后面的清除所有core文件函数
* checkInterval 循环间隔为600秒
* 总结：两种情况需要进行清理
  * 同名文件超过3个，清理先创建的
  * df 当前分区磁盘可用空间超过10G，则core文件全部清理

### 清理脚本的安装和添加

#### 安装脚本的修改

* 目录 `OS/install_os`

* 清理脚本在安装系统后进行相应的安装并且将脚本添加到系统启动执行的配置文件中 `rc.d`

  ```shell
  function install_core_file_clean()
  {
      [ ! -d /cloud/share/ ] && mkdir -p /cloud/share/
      action "copy ${cur_dir}/command/CoreFileCleaner.sh to /cloud/share/"   cp -rf ${cur_dir}/command/CoreFileCleaner.sh /cloud/share/
      echo "sh /cloud/share/CoreFileCleaner.sh" >> /etc/rc.d/rc.local
  }
  
  function install_common()
  {
      ......
      install_core_file_clean
      ......
  }
  ```

#### 添加或新建脚本

* `CoreFileCleaner.sh`添加在 `OS/command/`目录下

### 打桩测试

* 删除掉core清理脚本相关的文件（脚本、core目录、日志目录等），以及删除rc.local里执行core脚本的代码，结束清理脚本的进程

  ```bash
  [root @localhost ~/install_tmp/system_tar/OS]# ps -ef | grep Core
  root       3599      1  0 10:28 ?        00:00:00 sh /cloud/share/CoreFileCleaner.sh
  root      54682  52803  0 20:08 pts/0    00:00:00 grep --color=auto Core
  [root @localhost ~/install_tmp/system_tar/OS]# kill -9 3599
  ```

* 调用 DH-CSS7336IA-MSMR 里面的 install_product_system 函数，重新安装测试

	```shell
    function install_product_system()
    {
        (
            cd OS
            source ./install_os
            if [[ ${OS_VERSION} == 'OS7.7' ]]; then 
                OS7X7_install_os || exit 1
            else 
                install_os || exit 1 
            fi
        ) || return 1

        return 0
    }
	```

* 重启，查看进程，core文件清理脚本正常运行，并且有日志文件生成

  ```bash
  [root @localhost ~]# ps -ef | grep Core
  root       5228      1  0 20:26 ?        00:00:00 sh /cloud/share/CoreFileCleaner.sh
  root      20143  17694  0 20:27 pts/0    00:00:00 grep --color=auto Core
  ```



* **验证过程发现原 CoreFileCleaner.sh 脚本存在问题：**
* 重启后发现core文件达到清理条件后，不会按照脚本进行相应的清理；
    原因：重启之后由于`/proc/sys/kernel/core_pattern`文件里面的值是
    `|/usr/libexec/abrt-hook-ccpp %s %c %p %u %g %t %e %P %I %h`
    
    之后，又恢复成预设的值
     `/cloud/dahua/core/core-%e`
    所以导致重启后，脚本中core路径赋值为`/root/`,而不是`/cloud/dahua/core/`，清理脚本只会清理`root`路径的core文件；
    然而，之后系统生成的core文件却在`/cloud/dahua/core/`路径，脚本不会对该路径进行core文件清理，与预期不符。
    
  * 解决办法：每次循环，对core路径进行赋值，以防止core路径更改了，却不会进行相应的清理。（修改：添加set_core_path函数，在主循环中调用）

```shell
......
# CORE_PATH 赋值
function set_core_path()
{
    grep -q "|" /proc/sys/kernel/core_pattern
    if [ $? -eq 0 ]; then
        CORE_PATH="/root/"
    else
        ......
        CORE_PATH=`echo "$core_pattern" | awk -F "$pattern" '{print $1}'`
    fi
}
......
while true; do
    # 每次循环都进行core路径赋值，防止core路径更改了不会进行相应的清理
    set_core_path
	......
done &
```



* 验证Core文件清理脚本是否能正常清理文件
  **1.修改新安装的 CoreFileCleaner.sh 的一些变量方便测试**，如执行间隔 checkInterval，和目录大小限制CORE_PATH_LIMIT_SIZE；重新启动

  ```shell
  checkInterval=60
  CORE_PATH_LIMIT_SIZE=454000000
  ```
  
  **2.测试 clear_core_files 函数**
  
  * 使用` kill -s SIGSEGV $$` 命令生成四个同类型core文件
  
  ```bash
  [root @localhost /cloud/dahua/core]# ll
  -rw-------. 1 root root 1445888 Aug 11 14:42 core-bash.142050
  -rw-------. 1 root root 1445888 Aug 11 14:42 core-bash.2539
  -rw-------. 1 root root 1445888 Aug 10 20:41 core-bash.58539
  -rw-------. 1 root root 1445888 Aug 11 14:47 core-bash.70261
  ```
  
  * 过一段时间，发现只剩三个 core-bash 文件，说明 clear_core_files 函数正常运行，即超过三个同名文件时，则删除最先创建的core文件
  
  ```bash
  [root @localhost /cloud/dahua/core]# ll
  -rw-------. 1 root root 1445888 Aug 11 14:42 core-bash.142050
  -rw-------. 1 root root 1445888 Aug 11 14:42 core-bash.2539
  -rw-------. 1 root root 1445888 Aug 11 14:47 core-bash.70261
  ```
  
  **3.测试 clear_all_core_files 函数**
  
  * 创建一个一定大小的文件，命名按照core文件命名，让分区可用空间小于`CORE_PATH_LIMIT_SIZE`
  
  ```bash
  [root @localhost /cloud/dahua/core]# touch core-test.123
  [root @localhost /cloud/dahua/core]# dd if=/dev/zero of=core-test.123 count=1 bs=400M
  [root @localhost /cloud/dahua/core]# ll
  total 412072
  -rw-r--r--. 1 root root         0 Aug 11 17:01 core-bash.4
  -rw-------. 1 root root   1445888 Aug 11 17:02 core-bash.96576
  -rw-------. 1 root root   1445888 Aug 11 17:02 core-bash.97445
  -rw-r--r--. 1 root root 419430400 Aug 11 17:42 core-test.123
  ```
  
  * 到达一定时间后，core目录文件全部清空，说明 clear_all_core_files 函数正常运行，即分区空间小于预设值，则清理所有core文件
  
  ```shell
  [root @localhost /cloud/dahua/core]# ll
  total 0
  ```
  
  

## 上库记录

上库记录：https://yfgitlab.dahuatech.com/BigData/CloudStorage/CSS-Product/commit/45248f8a242e179ad91473ce1e11db9a08d0cd40
<pre>
fix：DN纯软部署场景下core文件数量进行控制
1、DN纯软包中 OS/install_os 添加对 CoreFileCleaner 脚本的安装
2、添加 CoreFileCleaner.h 到 OS/command/ 目录下
3、修复 CoreFileCleaner 中core文件路径设置错误的问题，增加了更新core文件路径函数
redmine #69678
修改人：余旭伟
</pre>